# ðŸ§  Agente Inteligente de Lista de Compras (MCP)

Este projeto implementa um **agente inteligente baseado em MCP (Model Context Protocol)**, capaz de gerenciar uma lista de compras usando comandos de voz e salvar os produtos em uma planilha Excel. O agente tambÃ©m permite enviar a lista via WhatsApp usando um link prÃ©-preenchido.

## âœ¨Como funciona

O agente escuta comandos de voz, interpreta a linguagem natural com um modelo LLM, atualiza a planilha Excel e envia a lista via WhatsApp se solicitado.
Todas as alteraÃ§Ãµes sÃ£o salvas automaticamente, sem interface grÃ¡fica.

## âœ¨Funcionalidades do Agente

- Aceita **comandos de voz** para:
  - Adicionar produtos
  - Remover produtos
  - Listar produtos
  - Enviar lista via WhatsApp
- MantÃ©m a lista de compras em **arquivo Excel (`.xlsx`)**
- IntegraÃ§Ã£o com **modelo LLM gratuito** (via Ollama/LangChain) para interpretar linguagem natural
- NÃ£o possui interface grÃ¡fica; todo funcionamento Ã© via terminal

---

## âœ¨Bibliotecas utilizadas

- **openpyxl** â€” manipulaÃ§Ã£o de planilhas Excel  
- **sounddevice** â€” entrada de voz  
- **vosk** â€” reconhecimento de voz offline  
- **langchain-ollama** â€” processamento de linguagem natural   
- **webbrowser** â€” envio da lista via WhatsApp  

> Obs.: Todas as bibliotecas sÃ£o gratuitas e compatÃ­veis com Python 3.10+.

---

## âœ¨ Como executar

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/seu-usuario/nome-do-repositorio.git
cd nome-do-repositorio
```

2. Instale as dependÃªncias (estÃ£o todas em um Ãºnico arquivo)
```bash
pip install -r requirements.txt
```
## âœ¨ Estrutura principal do projeto
```bash
â”œâ”€â”€ agenteMCP.py # Script principal do agente
â”œâ”€â”€ planilha.py # Gera a planilha lista_compras.xlsx
â”œâ”€â”€ requirements.txt # DependÃªncias do projeto
â”œâ”€â”€ vosk-model-small/ # Modelo de reconhecimento de voz
â””â”€â”€ README.md # Este arquivo
```

## âœ¨ ConfiguraÃ§Ã£o do Ollama e Modelo Mistral

O **Ollama** permite rodar modelos de linguagem grandes (LLMs) localmente, sem depender de APIs externas.  
No projeto, usamos o modelo **Mistral** para interpretar comandos de voz.

### Passo a passo

#### 1. InstalaÃ§Ã£o do Ollama

- Baixe o instalador do site oficial: [https://ollama.com](https://ollama.com)  
- Execute o instalador e abra o `Ollama.exe` pelo menos uma vez.

#### 2. Baixando o modelo Mistral

- VÃ¡ atÃ© a pasta do Ollama pelo terminal
 ```bash
cd "C:\Users\SeuUsuario\AppData\Local\Programs\Ollama\"
```
- Baixe o Mistral
```bash
ollama pull mistral
```

#### 3. IntegraÃ§Ã£o no Python

```python
from langchain_community.llms import Ollama
llm = Ollama(model="mistral")

from langchain_ollama import OllamaLLM
llm = OllamaLLM(model="mistral")


